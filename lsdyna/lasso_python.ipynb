{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read d3plot from LS-DYNA using lasso-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_d3plot import *\n",
    "\n",
    "path_to_d3plot = r'C:\\Users\\272766h\\Curtin University of Technology Australia\\Zitong Wang - Data generation\\C30_120mm\\0.4_10\\d3plot'\n",
    "d3plot = D3plot(path_to_d3plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_trajectory_type_strain(d3plot):\n",
    "    \"\"\"Read particle (element) trajectory of coordinates.\n",
    "    \n",
    "    Input: the d3plot data\n",
    "    Output: particle_trajectories of shape [ntimesteps, nparticles, 3]\n",
    "    \"\"\"\n",
    "    \n",
    "    ## node_displacement is actually node coords in all steps, shape [nstep, nnodes, 3]\n",
    "    node_trajectories = d3plot.arrays[\"node_displacement\"]\n",
    "    ## Each solid element (cubic) is defined by 8 nodes\n",
    "    # element_solid_node_indexes = d3plot.arrays[\"element_solid_node_indexes\"]\n",
    "    ## each beam involves 2 nodes, but the array shows 5 with 3rd being the same as 2nd\n",
    "    ## and 4th, 5th looks unrelated\n",
    "    ## Using LS-PrePost outputs 3 nodes per beam, with 3rd also being the same as 2nd\n",
    "    ## Therefore, only the first 2 nodes are used\n",
    "    element_beam_node_indexes = d3plot.arrays[\"element_beam_node_indexes\"][:, :2]\n",
    "    \n",
    "    # Convert the solid node indexes to a set for quick look-up\n",
    "    sph_node_indexes = d3plot.arrays[\"sph_node_indexes\"]\n",
    "    SPH_trajectories = node_trajectories[:, sph_node_indexes, :]\n",
    "\n",
    "    element_beam_node_indexes = np.unique(element_beam_node_indexes)\n",
    "    \n",
    "    element_beam_trajectories = node_trajectories[:, element_beam_node_indexes, :]\n",
    "\n",
    "    particle_trajectories = np.concatenate((SPH_trajectories, element_beam_trajectories), axis=1)\n",
    "\n",
    "    # Derive particle types, 0 concrete, 1 rebar, 2 boundary\n",
    "    # boundary is always 150 mm on the two ends of y-axis\n",
    "    SPH_types = np.zeros(SPH_trajectories.shape[1])\n",
    "    beam_types = np.ones(element_beam_trajectories.shape[1])\n",
    "    particle_type = np.concatenate((SPH_types, beam_types), axis=0)\n",
    "    LEFT_BOUNDARY = -855    # particle_trajectories[0, :, 1].min() + 150, this not aligned with the data from txt\n",
    "    RIGHT_BOUNDARY = 855    # particle_trajectories[0, :, 1].max() - 150\n",
    "    mask = (particle_trajectories[0, :, 1] >= RIGHT_BOUNDARY) | (particle_trajectories[0, :, 1] <= LEFT_BOUNDARY)\n",
    "    particle_type[mask] = 2\n",
    "    \n",
    "    # Strain\n",
    "    solid_eps = d3plot.arrays[\"element_solid_effective_plastic_strain\"][:, :, 0]\n",
    "    beam_eps = np.zeros((solid_eps.shape[0], element_beam_trajectories.shape[1]))\n",
    "    particle_strains = np.concatenate((solid_eps, beam_eps), axis=1)\n",
    "    \n",
    "    return particle_trajectories, particle_type, particle_strains\n",
    "\n",
    "particle_trajectories, particle_type, particle_strains = extract_trajectory_type_strain(d3plot)\n",
    "\n",
    "print(particle_trajectories.shape)\n",
    "print(particle_strains.shape)\n",
    "print(particle_type.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce monotonical increasing EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def enforce_eps_non_decreasing(particle_strains):\n",
    "    # Compute the differences between adjacent time steps\n",
    "    strains_diff = np.diff(particle_strains, axis=0)\n",
    "\n",
    "    # Set any negative differences to zero\n",
    "    strains_diff[strains_diff < 0] = 0\n",
    "\n",
    "    # Reconstruct the corrected strains using cumulative sum,\n",
    "    # starting with the initial strain values\n",
    "    corrected_strains = np.concatenate((particle_strains[:1, :], strains_diff), axis=0).cumsum(axis=0)\n",
    "    return corrected_strains\n",
    "\n",
    "particle_strains = enforce_eps_non_decreasing(particle_strains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling data\n",
    "- The provided data in d3plot should have timestep=0.01ms\n",
    "- FGN subsample that with a factor of 6, resulting in timestep=0.06ms\n",
    "- FGN requires 10 steps (or 0.6ms) to initilise\n",
    "- Therefor, given whatever data (>0.6ms) we need to downsample first and then extract the last 10 steps\n",
    "- CAUTION: EPS must be converted to monotonically increasing EPS before downsampling. Otherwise it results in peak missing\n",
    "- That's because the element erosion will result in element_eps=0 after reaching threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SEQUENCE_LENGTH = 10\n",
    "STEP_SIZE = 6\n",
    "\n",
    "def timestep_downsample(particle_trajectories, particle_strains):\n",
    "    particle_trajectories_downsampled = particle_trajectories[::STEP_SIZE]\n",
    "    particle_trajectories_downsampled = particle_trajectories_downsampled[-INPUT_SEQUENCE_LENGTH:]\n",
    "    \n",
    "    particle_strains_downsampled = particle_strains[::STEP_SIZE]\n",
    "    # Convert EPS to ResEPS (residual eps)\n",
    "    strains_diff = np.diff(particle_strains_downsampled, axis=0)\n",
    "    ## The initial strain should be the strain at step=-10 after downsampling\n",
    "    init_strains = particle_strains_downsampled[-INPUT_SEQUENCE_LENGTH:-INPUT_SEQUENCE_LENGTH+1, :]\n",
    "    ## The final ResEPS should combine the init_strain and following 9 steps of strain_dff\n",
    "    particle_strains_downsampled = np.concatenate((init_strains, strains_diff[-INPUT_SEQUENCE_LENGTH+1:]), axis=0)\n",
    "    \n",
    "    return particle_trajectories_downsampled, particle_strains_downsampled\n",
    "\n",
    "particle_trajectories, particle_resStrains = timestep_downsample(particle_trajectories, particle_strains)\n",
    "print(particle_trajectories.shape, particle_resStrains.shape)                                                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_integrity(particle_trajectories, particle_strains, particle_type):\n",
    "    nstep, nparticles, dim = particle_trajectories.shape\n",
    "    \n",
    "    # Shape check:\n",
    "    assert particle_type.shape == (nparticles,), \"Mismatch in shapes: particle_type\"\n",
    "    assert particle_strains.shape == (nstep, nparticles), \"Mismatch in shapes: particle_strains\"\n",
    "    assert particle_trajectories.shape[0] == particle_strains.shape[0] == 10, \"INPUT_SEQUENCE_LENGTH is not 10\"\n",
    "    \n",
    "    # Missing value check\n",
    "    for array, name in zip([particle_trajectories, particle_type, particle_strains],\n",
    "                           [\"particle_trajectories\", \"particle_type\", \"particle_strains\"]):\n",
    "        if np.any(np.isnan(array)):\n",
    "            print(f\"Missing values detected in {name}\")\n",
    "    \n",
    "    # Value Range CHecks:\n",
    "    for i, axis in enumerate([\"x\", \"y\", \"z\"]):\n",
    "        print(f\"{axis}-axis min: {np.min(particle_trajectories[:, :, i]):.2f}, max: {np.max(particle_trajectories[:, :, i]):.2f}\")\n",
    "    \n",
    "    if np.any((particle_strains < 0) | (particle_strains > 2)):\n",
    "        print(\"Effective Plastic strain values out of range [0, 2]\")\n",
    "        \n",
    "\n",
    "check_data_integrity(particle_trajectories, particle_resStrains, particle_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = particle_ResStrains\n",
    "nstep = data.shape[0]\n",
    "nnode = data.shape[1]\n",
    "\n",
    "# Randomly pick 20 nodes\n",
    "random_nodes = np.random.choice(particle_strains.shape[1], 30, replace=False)\n",
    "\n",
    "# Initialize the plot with subplots in 2 or 3 rows\n",
    "nrows = 3  # You can change this to 2 if you prefer\n",
    "ncols = int(np.ceil(30 / nrows))\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 7))\n",
    "\n",
    "# Flatten the axes array for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the eps history for the selected nodes\n",
    "for i, node in enumerate(random_nodes):\n",
    "    ax = axes[i]\n",
    "    ax.plot(data[:, node])\n",
    "    ax.set_title(f'Node {node}')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Eps')\n",
    "\n",
    "# Remove any unused subplots\n",
    "for i in range(len(random_nodes), nrows * ncols):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Add a main title\n",
    "plt.suptitle('Eps History for Randomly Selected Nodes')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydyna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
