{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9e266cd-aea1-48cd-9e76-ef9ccbdbbb45",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pre-process and write to npz for GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a50bd9-d350-4cb8-8679-29bcd6379ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "       \n",
    "\n",
    "dataset = 'Concrete3D'\n",
    "in_dir = f'/home/jovyan/share/gns_data/Concrete3D/DYNA_one/'\n",
    "out_dir = f'/home/jovyan/share/gns_data/{dataset}/'\n",
    "pathlib.Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STRAIN_MEAN, STRAIN_STD = 0.5426821307442955, 0.7741500060379738\n",
    "\n",
    "# Grab all simulation cases from corresponding data folder\n",
    "simulations = glob.glob(in_dir +'*')\n",
    "random.shuffle(simulations)\n",
    "\n",
    "## Larger step size leads to shorter trajectory and hence better rollout performance\n",
    "## But lower precision of the simulation\n",
    "## Current simulation are of absolute time 30 ms\n",
    "## Step size=1 means 53 steps, each of which 0.6 ms\n",
    "STEP_SIZE = 1\n",
    "\n",
    "## Initialisation placeholders for data\n",
    "n_trajectory = len(simulations)\n",
    "ds_train, ds_valid, ds_test = {}, {}, {}\n",
    "vels = np.array([]).reshape(0, 3)\n",
    "accs = np.array([]).reshape(0, 3)\n",
    "strain_stats = np.array([])\n",
    "file_train, file_valid, file_test = [], [], []\n",
    "\n",
    "## Main loop for data extraction\n",
    "for idx, simulation in enumerate(simulations):\n",
    "    print(f\"{idx}/{n_trajectory} Reading {simulation}...\")\n",
    "    positions, particle_types, strains = parse_simulation_with_errosion(simulation)\n",
    "    dim = positions.shape[-1]\n",
    "    \n",
    "    positions = positions[::STEP_SIZE, :, :]\n",
    "    \n",
    "    strains = strains[::STEP_SIZE, :]\n",
    "    strains = (strains - STRAIN_MEAN) / STRAIN_STD   ## standardize based on overall mean and std\n",
    "    \n",
    "    # print for debug\n",
    "    print(f\"Dim: {dim}\")\n",
    "    print(f\"Position min:{positions.min(axis=(0,1))}, max:{positions.max(axis=(0,1))}\")\n",
    "    print(f\"Strain min:{strains.min(axis=(0,1))}, max:{strains.max(axis=(0,1))}\")\n",
    "    print(f\"Shape, pos: {positions.shape}, types: {particle_types.shape}, strain: {strains.shape}\")\n",
    "    print(f\"Unique particle types: {np.unique(particle_types)}\")\n",
    "    \n",
    "    # Data splits: train(80%), valid(10%), test(10%)\n",
    "    key = f'trajectory_{idx}' \n",
    "    if True:\n",
    "        print('to valid')\n",
    "        ds_valid[key] = [positions, particle_types, strains]\n",
    "        file_valid.append(simulation)\n",
    "    if True:\n",
    "        print('to test')\n",
    "        ds_test[key] = [positions, particle_types, strains]\n",
    "        file_test.append(simulation)\n",
    "    if True:\n",
    "        print('to train')\n",
    "        ds_train[key] = [positions, particle_types, strains]\n",
    "        file_train.append(simulation)\n",
    "        \n",
    "    # Extract Vel and Acc statistics\n",
    "    # positions of shape [timestep, particles, dimensions]\n",
    "    vel_trajectory = positions[1:,:,:] - positions[:-1,:,:]\n",
    "    acc_trajectory = vel_trajectory[1:,:,:]- vel_trajectory[:-1,:,:]\n",
    "    \n",
    "    vels = np.concatenate((vels, vel_trajectory.reshape(-1, dim)), axis=0)\n",
    "    accs = np.concatenate((accs, acc_trajectory.reshape(-1, dim)), axis=0)\n",
    "\n",
    "# Extract vel, acc statistics for normalisation\n",
    "vel_mean, vel_std = list(vels.mean(axis=0)), list(vels.std(axis=0))\n",
    "acc_mean, acc_std = list(accs.mean(axis=0)), list(accs.std(axis=0))\n",
    "\n",
    "# Save datasets in numpy format\n",
    "np.savez(out_dir + 'train.npz', **ds_train)\n",
    "np.savez(out_dir + 'valid.npz', **ds_valid)\n",
    "np.savez(out_dir + 'test.npz', **ds_test)\n",
    "\n",
    "print(f\"{len(ds_train)} trajectories saved to train.npz.\")\n",
    "print(f\"{len(ds_valid)} trajectories saved to valid.npz.\")\n",
    "print(f\"{len(ds_test)}  trajectories saved to test.npz.\")\n",
    "\n",
    "# Save meta data\n",
    "in_file = '/home/jovyan/share/gns_data/Concrete2D-C/metadata.json'\n",
    "out_file = f'/home/jovyan/share/gns_data/{dataset}/metadata.json'\n",
    "\n",
    "with open(in_file, 'r') as f:\n",
    "    meta_data = json.load(f)\n",
    "\n",
    "# In GNN, the suggested connection radius is 4.5r, or 5.625 mm (aounrd 20 neighbors)\n",
    "# If R is 5 mm before normalization, \n",
    "meta_data['dim'] = 3\n",
    "meta_data['default_connectivity_radius'] = 15 \n",
    "meta_data['sequence_length'] = positions.shape[0]\n",
    "meta_data['vel_mean'] = vel_mean\n",
    "meta_data['vel_std'] = vel_std\n",
    "meta_data['acc_mean'] = acc_mean\n",
    "meta_data['acc_std'] = acc_std\n",
    "meta_data['strain_mean'] = STRAIN_MEAN\n",
    "meta_data['strain_std'] = STRAIN_STD\n",
    "\n",
    "meta_data['dt'] = 0.0006 * STEP_SIZE\n",
    "meta_data['bounds'] = [[-10, 1710], [-20, 170], [-20, 430]]\n",
    "meta_data['file_train'] = file_train\n",
    "meta_data['file_valid'] = file_valid\n",
    "meta_data['file_test'] = file_test\n",
    "print(meta_data)\n",
    "\n",
    "with open(out_file, 'w') as f:\n",
    "    json.dump(meta_data, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a710e1a5-0882-4856-b6b6-c79ebbb246bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parse LS-DYNA text file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78de6866",
   "metadata": {},
   "source": [
    "## with errosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0c961-596a-4dd6-9232-02ed6d5bcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# regular expression for finding numbers, int and scientific\n",
    "re_int_sci = r'[-\\d\\.]+e?[-+\\d]*'\n",
    "re_sci = r'[+-]?\\d+\\.\\d+e[+-]?[\\d]+'\n",
    "\n",
    "def parse_simulation_with_errosion(file):\n",
    "    '''\n",
    "    Extract info from LSDYNA txt.\n",
    "        \n",
    "    Input: text file, e.g., 20MPa, 30Mpa. The text file is extracted with the following steps:\n",
    "        1. Load d3plot file and unselect the parts 'weight' and 'load cell'\n",
    "        2. Output the 'Element' for 'Active parts only' (particle type)\n",
    "        3. Output 'Element Centroid, Volume' by appending all steps (pos)\n",
    "        4. Further unselect parts 'long','hoop', select 'eps' and Output 'Element results' and append all (eps)\n",
    "        5. Further unselect 'beam', 'head', select 'long' and 'hoop', select 'axial strain', \n",
    "        6. and Output 'Element results' and append all (axs)\n",
    "        \n",
    "    The resulted txt file contains:\n",
    "        1. The init particle id (eid) with part id (pid)\n",
    "        2. For each timestep:\n",
    "            2.1 solid particle position (pid,x,y,z)\n",
    "            2.2 beam particle position (pid,x,y,z)\n",
    "        3. For each timestep, the solid particle strain (eps) (pid, eps)\n",
    "        4. And then for each timestep, the beam particle strain (axs) (pid, eps)\n",
    "    Note if element errosion is adopted, the num_particle per timestep may vary,\n",
    "    but eliminated particles are consistent between position and strain\n",
    "    \n",
    "    Output: np arrays\n",
    "            tracjectory: (timesteps, num_particles, 3), \n",
    "            particle_types: (timesteps, num_particles),  # if with errosion\n",
    "            strains: (timesteps, num_particles).       \n",
    "    '''\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    ## Concrete-2D-CI particle types based on particle index\n",
    "    PID_TO_TYPE = {1:0,   # Beam\n",
    "                   4:1,   # Head (same material with load cell)\n",
    "                   5:2,   # Long\n",
    "                   6:3    # Hoop\n",
    "                  }\n",
    "\n",
    "    # Extract all lines of interest\n",
    "    pos_lines_start = []\n",
    "    solid_strain_lines_start = []\n",
    "    beam_strain_lines_start = []\n",
    "    end_line = []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith(\"*ELEMENT_SOLID\"):\n",
    "            type_line_start = idx\n",
    "        elif line.startswith(\"$Eid, X, Y, Z, Volume\"):\n",
    "            pos_lines_start.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Effective Plastic Strain (Unaveraged)\"):\n",
    "            solid_strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Axial Strain (Unaveraged)\"):  \n",
    "            beam_strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"*END\"):  # $NODAL_RESULTS,(1d) *INITIAL_VELOCITY_NODE(2d)\n",
    "            end_lines.append(idx)\n",
    "\n",
    "    type_line_end = end_lines[0]    # the first *END is for particle type\n",
    "    num_timesteps = len(pos_lines_start)\n",
    "    pos_lines_end = end_lines[1:num_timesteps+1]\n",
    "    solid_strain_lines_end = end_lines[num_timesteps+1:2*num_timesteps+1]\n",
    "    beam_strain_lines_end = end_lines[2*num_timesteps+1:]\n",
    "\n",
    "    # Extact particle types\n",
    "    init_particle_type = []\n",
    "    eids = []\n",
    "    for line in lines[type_line_start:type_line_end]:\n",
    "        num_str = re.findall(re_int_sci, line)  # Regular expression findign integers\n",
    "        if len(num_str) >= 4:\n",
    "            eid = int(num_str[0])\n",
    "            pid = int(num_str[1])\n",
    "            particle_type = PID_TO_TYPE[pid]\n",
    "            eids.append(eid)\n",
    "            init_particle_type.append((eid, particle_type))\n",
    "    init_particle_type = np.array(init_particle_type).astype(int)\n",
    "\n",
    "    # Extact particle positions \n",
    "    trajectory, solid_strains, beam_strains, particle_types = [], [], [], []\n",
    "    type_dict = dict(init_particle_type)\n",
    "    # Extract step by step, due to dynamic element errsion\n",
    "    for idx in range(len(pos_lines_start)):\n",
    "        line_start, line_end = pos_lines_start[idx]+1, pos_lines_end[idx]\n",
    "        pos_lines = lines[line_start:line_end]\n",
    "        line_start, line_end = solid_strain_lines_start[idx]+1, solid_strain_lines_end[idx]\n",
    "        solid_strain_lines = lines[line_start:line_end]\n",
    "        line_start, line_end = beam_strain_lines_start[idx]+1, beam_strain_lines_end[idx]\n",
    "        beam_strain_lines = lines[line_start:line_end]\n",
    "        \n",
    "        # Extract axial strain for beams (axs)\n",
    "        beam_strain_one_step = []\n",
    "        for line in beam_strain_lines:\n",
    "            beam_strain_str = re.findall(re_int_sci, line)\n",
    "            if len(beam_strain_str) == 2:\n",
    "                beam_strain_float = [float(x) for x in beam_strain_str] # [eid, axs]\n",
    "                beam_strain_one_step.append(tuple(beam_strain_float))\n",
    "        beam_strain_one_step = np.array(beam_strain_one_step).astype(float)\n",
    "        \n",
    "        # Extract eps strain for solids (eps)\n",
    "        solid_strain_one_step = []\n",
    "        for strain_line in solid_strain_lines:\n",
    "            strain_str = re.findall(re_int_sci, strain_line)\n",
    "            if len(strain_str) == 2:\n",
    "                strain_float = [float(x) for x in strain_str] # [eid, eps]\n",
    "                solid_strain_one_step.append(tuple(strain_float))   \n",
    "        solid_strain_one_step = np.array(solid_strain_one_step)\n",
    "        \n",
    "        # Extract position for all particles\n",
    "        pos_one_step = []\n",
    "        for pos_line in pos_lines:\n",
    "            pos_str = re.findall(re_int_sci, pos_line)\n",
    "            if len(pos_str) >= 4:\n",
    "                pos_float = [float(x) for x in pos_str[:4]] # [eid, x, y, z]\n",
    "                pos_one_step.append(tuple(pos_float))\n",
    "        pos_one_step = np.array(pos_one_step)\n",
    "        \n",
    "        pos_dict = {item[0]: item[1:] for item in pos_one_step}\n",
    "        solid_strain_dict = {item[0]: item[1:] for item in solid_strain_one_step}\n",
    "        \n",
    "        # As there is errosion for pos and solid strain, we updated them base one\n",
    "        # the full list of ID (key) presented in the init_particle_type\n",
    "        # The deleted particle id will be impute with 0 for pos and strain\n",
    "        # The particle type will change to 4\n",
    "        for key in type_dict:\n",
    "            if key not in pos_dict and type_dict[key] != 2 and type_dict[key] != 3:\n",
    "                pos_dict[key] = [0., 0., 0.]\n",
    "                solid_strain_dict[key] = [0.]\n",
    "                type_dict[key] = 4\n",
    "        pos_one_step_updated = np.array([[k] + list(v) for k, v in pos_dict.items()]).astype(float)\n",
    "        solid_strain_one_step_updated = np.array([[k] + list(v) for k, v in solid_strain_dict.items()]).astype(float)\n",
    "        particle_type_updated = np.array(list(type_dict.items())).astype(int)\n",
    "        \n",
    "        # Append data of one time step to lists\n",
    "        trajectory.append(pos_one_step_updated)\n",
    "        solid_strains.append(solid_strain_one_step_updated)\n",
    "        particle_types.append(particle_type_updated)\n",
    "        beam_strains.append(beam_strain_one_step)\n",
    "        \n",
    "    trajectory = np.array(trajectory).astype(float)\n",
    "    particle_types = np.array(particle_types).astype(int)\n",
    "    strains = np.concatenate((np.array(solid_strains), np.array(beam_strains)), axis=1).astype(float)\n",
    "\n",
    "    # Sort data based on particle id\n",
    "    for step in range(num_timesteps):\n",
    "        sorted_idx = particle_types[step, :, 0].argsort()\n",
    "        particle_types[step, :] = particle_types[step, sorted_idx]\n",
    "\n",
    "        sorted_idx = strains[step, :, 0].argsort()\n",
    "        strains[step, :] = strains[step, sorted_idx]\n",
    "        \n",
    "        sorted_idx = trajectory[step, :, 0].argsort()\n",
    "        trajectory[step, :] = trajectory[step, sorted_idx]\n",
    "\n",
    "    # Discard id\n",
    "    trajectory = trajectory[:, :, 1:]\n",
    "    strains = strains[:, :, 1]\n",
    "    particle_types = particle_types[:,:,1]\n",
    "\n",
    "    print('trajectory: ', trajectory.shape)\n",
    "    print('particle_types: ', particle_types.shape)\n",
    "    print('strains :', strains.shape)\n",
    "    \n",
    "    return trajectory, particle_types, strains\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5ba1349",
   "metadata": {},
   "source": [
    "## without errosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# regular expression for finding numbers, int and scientific\n",
    "re_int_sci = r'[-\\d\\.]+e?[-+\\d]*'\n",
    "re_sci = r'[+-]?\\d+\\.\\d+e[+-]?[\\d]+'\n",
    "\n",
    "def parse_simulation(file):\n",
    "    '''\n",
    "    Extract info from LSDYNA txt.\n",
    "        \n",
    "    Input: text file, e.g., 20MPa, 30Mpa. The text file is extracted with the following steps:\n",
    "        1. Load d3plot file and unselect the parts 'weight' and 'load cell'\n",
    "        2. Output the 'Element' for 'Active parts only' (particle type)\n",
    "        3. Output 'Element Centroid, Volume' by appending all steps (pos)\n",
    "        4. Further unselect parts 'long','hoop', select 'eps' and Output 'Element results' and append all (eps)\n",
    "        5. Further unselect 'beam', 'head', select 'long' and 'hoop', select 'axial strain', \n",
    "        6. and Output 'Element results' and append all (axs)\n",
    "        \n",
    "    The resulted txt file contains:\n",
    "        1. The init particle id (eid) with part id (pid)\n",
    "        2. For each timestep:\n",
    "            2.1 solid particle position (pid,x,y,z)\n",
    "            2.2 beam particle position (pid,x,y,z)\n",
    "        3. For each timestep, the solid particle strain (eps) (pid, eps)\n",
    "        4. And then for each timestep, the beam particle strain (axs) (pid, eps)\n",
    "    \n",
    "    Output: np arrays\n",
    "            tracjectory: (timesteps, num_particles, 3), \n",
    "            particle_types: (num_particles),  # if without errosion\n",
    "            strains: (timesteps, num_particles).       \n",
    "    '''\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    pos_lines_start, end_lines = [], []\n",
    "    solid_strain_lines_start, beam_strain_lines_start = [], []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith(\"*ELEMENT_SOLID\"):\n",
    "            type_line_start = idx\n",
    "        elif line.startswith(\"$Eid, X, Y, Z, Volume\"):\n",
    "            pos_lines_start.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Effective Plastic Strain (Unaveraged)\"):\n",
    "            solid_strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Axial Strain (Unaveraged)\"):  \n",
    "            beam_strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"*END\"):  # $NODAL_RESULTS,(1d) *INITIAL_VELOCITY_NODE(2d)\n",
    "            end_lines.append(idx)\n",
    "\n",
    "    type_line_end = end_lines[0]    # the first *END is for particle type\n",
    "    num_timesteps = len(pos_lines_start)\n",
    "    pos_lines_end = end_lines[1:num_timesteps+1]\n",
    "    solid_strain_lines_end = end_lines[num_timesteps+1:2*num_timesteps+1]\n",
    "    beam_strain_lines_end = end_lines[2*num_timesteps+1:]\n",
    "\n",
    "    # Extact particle types\n",
    "    particle_types = []\n",
    "    eids = []\n",
    "    for line in lines[type_line_start:type_line_end]:\n",
    "        num_str = re.findall(re_int_sci, line)  # Regular expression findign integers\n",
    "        if len(num_str) >= 4:\n",
    "            eid = int(num_str[0])\n",
    "            pid = int(num_str[1])\n",
    "            particle_type = PID_TO_TYPE[pid]\n",
    "            eids.append(eid)\n",
    "            particle_types.append((eid, particle_type))\n",
    "    particle_types = np.array(particle_types).astype(int)\n",
    "\n",
    "    # Extact particle positions \n",
    "    trajectory = []\n",
    "    for line_start, line_end in zip(pos_lines_start, pos_lines_end):\n",
    "        pos_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        pos_one_step = []\n",
    "        for line in pos_lines:\n",
    "            num_str = re.findall(re_int_sci, line)  # Regular expression findign scitific numbers\n",
    "            if len(num_str) >= 4:\n",
    "                pos = [float(x) for x in num_str[:4]] # [eid, x, y, z]\n",
    "                pos = tuple(pos)\n",
    "                pos_one_step.append(pos)\n",
    "        trajectory.append(pos_one_step) \n",
    "    trajectory = np.array(trajectory)\n",
    "\n",
    "    # Extract effective plastic strain for solids (eps)\n",
    "    solid_strains = []\n",
    "    for line_start, line_end in zip(solid_strain_lines_start, solid_strain_lines_end):\n",
    "        strain_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        strains_one_step = []\n",
    "        for line in strain_lines:\n",
    "            num_str = re.findall(re_int_sci, line)  # Regular expression findign scitific numbers\n",
    "            if len(num_str) == 2:\n",
    "                num = [float(x) for x in num_str]\n",
    "                strains_one_step.append(tuple(num))\n",
    "        solid_strains.append(strains_one_step)\n",
    "    solid_strains = np.array(solid_strains).astype(float)\n",
    "\n",
    "    # Extract axial strain for beams (axs)\n",
    "    beam_strains = []\n",
    "    for line_start, line_end in zip(beam_strain_lines_start, beam_strain_lines_end):\n",
    "        strain_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        strains_one_step = []\n",
    "        for line in strain_lines:\n",
    "            num_str = re.findall(re_int_sci, line)  # Regular expression findign scitific numbers\n",
    "            if len(num_str) == 2:\n",
    "                num = [float(x) for x in num_str]\n",
    "                strains_one_step.append(tuple(num))\n",
    "        beam_strains.append(strains_one_step)\n",
    "    beam_strains = np.array(beam_strains).astype(float)\n",
    "\n",
    "    # Concatenate solid and beam \n",
    "    strains = np.concatenate((solid_strains, beam_strains), axis=1)\n",
    "\n",
    "    # Sort based on eid\n",
    "    idx = particle_types[:, 0].argsort()\n",
    "    particle_types = particle_types[idx, 1]\n",
    "\n",
    "    idx = strains[0, :, 0].argsort()\n",
    "    strains = strains[:, idx, 1]\n",
    "\n",
    "    idx = trajectory[0, :, 0].argsort()\n",
    "    trajectory = trajectory[:, idx, 1:]\n",
    "\n",
    "    print('trajectory: ', trajectory.shape)\n",
    "    print('particle_types: ', particle_types.shape)\n",
    "    print('strains :', strains.shape)\n",
    "    \n",
    "    return trajectory, particle_types, strains\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fbb50e2",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc3b7c3a",
   "metadata": {},
   "source": [
    "## plot pos-time or strain-time for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bdb39-21ee-4410-9962-d93b54c98345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(strains[:, 41500])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6030fd9-c4e2-4e22-93c7-3c3e8671a802",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test regular expression for number extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25e860-bb0a-4645-9e5a-2b2a08a8cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "strs = ['20742   1.4952594e+03   -1.0499660e+02   1.6313647e-02   9.9995575e+02',\n",
    "        '    32365   1.4051317e+00',\n",
    "        '   10826       1   15757   15758   15784   15783   11311   11312   11338   11337',\n",
    "        '$Total Solid element Volume =    7.5878880e+07'\n",
    "       ]\n",
    "\n",
    "pattern = r'[+-]?\\d+\\.\\d+e[+-]?[\\d]+'\n",
    "for str in strs:\n",
    "    print(re.findall(pattern, str))\n",
    "    \n",
    "pattern = r'[-\\d\\.]+e?[-+\\d]*'\n",
    "for str in strs:\n",
    "    print(re.findall(pattern, str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "966eb557-29f5-4f3b-86f4-fd42353df575",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Modify metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f182a3-c205-46ce-9c02-e13ba4635842",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = '/home/jovyan/share/gns_data/Concrete3D/metadata.json'\n",
    "out_file = f'/home/jovyan/share/gns_data/Concrete3D/metadata.json'\n",
    "\n",
    "with open(in_file, 'r') as f:\n",
    "    meta_data_in = json.load(f)\n",
    "\n",
    "with open(out_file, 'r') as f:\n",
    "    meta_data_out = json.load(f)\n",
    "\n",
    "meta_data_out['dim'] = 3\n",
    "meta_data_out['bounds'] = [[-5, 1705], [-40, 190], [-20, 700]]\n",
    "\n",
    "for field in ['vel_mean', 'vel_std', 'acc_mean', 'acc_std']:\n",
    "    meta_data_out[field] = meta_data_in[field]\n",
    "\n",
    "print(meta_data_out)\n",
    "\n",
    "with open(out_file, 'w') as f:\n",
    "    json.dump(meta_data_out, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
