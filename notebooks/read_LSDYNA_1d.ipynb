{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766cfd39-b1a9-4e7a-b0f5-c5d152c16f7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Parse LSDYNA file to extract particle coordinate, type, effective plastic strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4f7237-0e16-4ce3-8936-e2edc7b64941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "LOADING_PARTICLES = []\n",
    "SUPPORT_PARTICLES = []\n",
    "\n",
    "def parse_simulation(file):\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find all \"particle position\" lines and \"plastic strain\" lines using key words\n",
    "    pos_lines_start, pos_lines_end = [], []\n",
    "    strain_lines_start, strain_lines_end = [], []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith(\"*NODE\"):\n",
    "            pos_lines_start.append(idx)\n",
    "        elif line.startswith(\"$NODAL_RESULTS\"):  # $NODAL_RESULTS,(1d) *INITIAL_VELOCITY_NODE(2d)\n",
    "            pos_lines_end.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Effective Plastic Strain\"):\n",
    "            strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"*END\"):  \n",
    "            strain_lines_end.append(idx)\n",
    "            \n",
    "    # Extact particle positions \n",
    "    trajectory = []\n",
    "    for line_start, line_end in zip(pos_lines_start, pos_lines_end):\n",
    "        pos_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        timestep = []\n",
    "        for line in pos_lines:\n",
    "            num_str = re.findall(r'[-\\d\\.e+]+', line)  # Regular expression findign scitific numbers\n",
    "            (x, y) = (float(num_str[1]), float(num_str[2]))\n",
    "            timestep.append((x,y))\n",
    "        timestep.append((x,y)) # Add one particle as an additional al boundary (as there are only 4 boundary particles but 5 concrete particles in one column)\n",
    "        trajectory.append(timestep) \n",
    "    \n",
    "    # Extact particle types\n",
    "    particle_types = []\n",
    "    pos_lines = lines[pos_lines_start[0]+1:pos_lines_end[0]]\n",
    "    for line in pos_lines:\n",
    "        num_str = re.findall(r'[-\\d\\.e+]+', line)\n",
    "        if int(num_str[0]) in LOADING_PARTICLES:\n",
    "            particle_types.append(3)   # kinematic particles\n",
    "        elif int(num_str[0]) in SUPPORT_PARTICLES:\n",
    "            particle_types.append(2)   # boundary particles (rigid)\n",
    "        else:\n",
    "            particle_types.append(1)   # normal concrete particles\n",
    "    particle_types.append(2)  # add one boundar particle type\n",
    "    # Extrac effective plastic strain\n",
    "    strains = []\n",
    "    for line_start, line_end in zip(strain_lines_start, strain_lines_end):\n",
    "        strain_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        strains_one_step = []\n",
    "        for line in strain_lines:\n",
    "            num_str = re.findall(r'[-+\\d\\.Ee]+', line)  # the expression matches one or more repetitions of \"-\", \"integer\", \".\", \"E\",\n",
    "            num = float(num_str[1])\n",
    "            strains_one_step.append(num)\n",
    "        strains_one_step.append(num)   # add one more strain value for the additional boundary particle (no effect, just keep the shape uniform)\n",
    "        strains.append(strains_one_step)     \n",
    "    \n",
    "\n",
    "    return np.array(trajectory).astype(np.float), np.array(particle_types).astype(np.float), np.array(strains).astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e266cd-aea1-48cd-9e76-ef9ccbdbbb45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pre-process and write to npz for GNN training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a50bd9-d350-4cb8-8679-29bcd6379ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_200_1.txt...\n",
      "Position min:[ 0.10403911 -0.0005664 ], max:[0.46428571 1.0005664 ]\n",
      "Strain min:-0.021641, max:0.0216253\n",
      "Position shape:(101, 505, 2), type shape:(505,)\n",
      "Unique particle types: [1. 2.]\n",
      "1 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_200_2.txt...\n",
      "Position min:[ 0.09908228 -0.00124148], max:[0.46428571 1.00124148]\n",
      "Strain min:-0.043257, max:0.0433605\n",
      "Position shape:(101, 505, 2), type shape:(505,)\n",
      "Unique particle types: [1. 2.]\n",
      "2 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_200_4.txt...\n",
      "Position min:[ 0.08898621 -0.00238507], max:[0.46428571 1.00238507]\n",
      "Strain min:-0.085851, max:0.0860487\n",
      "Position shape:(101, 505, 2), type shape:(505,)\n",
      "Unique particle types: [1. 2.]\n",
      "3 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_200_8.txt...\n",
      "Position min:[ 0.06807272 -0.00438923], max:[0.46428571 1.00438923]\n",
      "Strain min:-0.17014, max:0.170763\n",
      "Position shape:(101, 505, 2), type shape:(505,)\n",
      "Unique particle types: [1. 2.]\n",
      "4 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_300_1.txt...\n",
      "Position min:[ 0.10152948 -0.0005664 ], max:[0.64285714 1.0005664 ]\n",
      "Strain min:-0.019231, max:0.0212661\n",
      "Position shape:(101, 755, 2), type shape:(755,)\n",
      "Unique particle types: [1. 2.]\n",
      "5 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_300_2.txt...\n",
      "Position min:[ 0.09403959 -0.00124148], max:[0.64285714 1.00124148]\n",
      "Strain min:-0.037804, max:0.0424618\n",
      "Position shape:(101, 755, 2), type shape:(755,)\n",
      "Unique particle types: [1. 2.]\n",
      "6 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_300_4.txt...\n",
      "Position min:[ 0.07879905 -0.00238507], max:[0.64285714 1.00238507]\n",
      "Strain min:-0.078679, max:0.084138\n",
      "Position shape:(101, 755, 2), type shape:(755,)\n",
      "Unique particle types: [1. 2.]\n",
      "7 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_300_8.txt...\n",
      "Position min:[ 0.0472254  -0.00438923], max:[0.64285714 1.00438923]\n",
      "Strain min:-0.16563, max:0.161138\n",
      "Position shape:(101, 755, 2), type shape:(755,)\n",
      "Unique particle types: [1. 2.]\n",
      "8 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_400_1.txt...\n",
      "Position min:[ 0.09900604 -0.0005664 ], max:[0.82142857 1.0005664 ]\n",
      "Strain min:-0.021376, max:0.0214072\n",
      "Position shape:(101, 1005, 2), type shape:(1005,)\n",
      "Unique particle types: [1. 2.]\n",
      "9 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_400_2.txt...\n",
      "Position min:[ 0.08903609 -0.00124148], max:[0.82142857 1.00124148]\n",
      "Strain min:-0.042639, max:0.0425102\n",
      "Position shape:(101, 1005, 2), type shape:(1005,)\n",
      "Unique particle types: [1. 2.]\n",
      "10 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_400_4.txt...\n",
      "Position min:[ 0.06897636 -0.00238507], max:[0.82142857 1.00238507]\n",
      "Strain min:-0.081523, max:0.0840484\n",
      "Position shape:(101, 1005, 2), type shape:(1005,)\n",
      "Unique particle types: [1. 2.]\n",
      "11 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_400_8.txt...\n",
      "Position min:[ 0.02788366 -0.00438923], max:[0.82142857 1.00438923]\n",
      "Strain min:-0.13939, max:0.177392\n",
      "Position shape:(101, 1005, 2), type shape:(1005,)\n",
      "Unique particle types: [1. 2.]\n",
      "12 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_500_1.txt...\n",
      "Position min:[ 0.09647583 -0.0005664 ], max:[1.        1.0005664]\n",
      "Strain min:-0.018299, max:0.0213652\n",
      "Position shape:(101, 1255, 2), type shape:(1255,)\n",
      "Unique particle types: [1. 2.]\n",
      "13 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_500_2.txt...\n",
      "Position min:[ 0.08395783 -0.00124148], max:[1.         1.00124148]\n",
      "Strain min:-0.036632, max:0.0425985\n",
      "Position shape:(101, 1255, 2), type shape:(1255,)\n",
      "Unique particle types: [1. 2.]\n",
      "14 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_500_4.txt...\n",
      "Position min:[ 0.05876066 -0.00238507], max:[1.         1.00238507]\n",
      "Strain min:-0.080571, max:0.0831819\n",
      "Position shape:(101, 1255, 2), type shape:(1255,)\n",
      "Unique particle types: [1. 2.]\n",
      "15 Reading /home/jovyan/share/gns_data/Concrete1D/LSDYNA/1d_500_8.txt...\n",
      "Position min:[ 0.0074662  -0.00438923], max:[1.         1.00438923]\n",
      "Strain min:-0.16056, max:0.165487\n",
      "Position shape:(101, 1255, 2), type shape:(1255,)\n",
      "Unique particle types: [1. 2.]\n",
      "13 trajectories parsed and saved to train.npz.\n",
      "3 trajectories parsed and saved to valid.npz.\n",
      "3  trajectories parsed and saved to test.npz.\n",
      "Positions shape (101, 1255, 2), Particle types shape (1255,), Strains shape (101, 1255)\n",
      "{'bounds': [[0, 1], [0, 1]], 'sequence_length': 101, 'default_connectivity_radius': 0.03, 'dim': 2, 'dt': 0.003, 'vel_mean': [3.6516893183094815e-05, -8.879035645930168e-15], 'vel_std': [0.001719571412839328, 0.00026315754547233703], 'acc_mean': [-1.6107241843507297e-05, -1.7935080854521518e-14], 'acc_std': [0.0004606544878019383, 0.00036184845719181724], 'file_train': ['1d_200_1.txt', '1d_200_2.txt', '1d_200_4.txt', '1d_200_8.txt', '1d_300_1.txt', '1d_300_4.txt', '1d_300_8.txt', '1d_400_1.txt', '1d_400_2.txt', '1d_400_8.txt', '1d_500_1.txt', '1d_500_2.txt', '1d_500_4.txt'], 'file_valid': ['1d_300_4.txt', '1d_400_8.txt', '1d_500_2.txt'], 'file_test': ['1d_300_2.txt', '1d_400_4.txt', '1d_500_8.txt']}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "dataset = 'Concrete1D'\n",
    "\n",
    "in_dir = f'/home/jovyan/share/gns_data/{dataset}/LSDYNA/'\n",
    "out_dir = f'/home/jovyan/share/gns_data/{dataset}/'\n",
    "STEP_SIZE = 3\n",
    "\n",
    "val_set = ['300_4', '400_8', '500_2']\n",
    "test_set = [ '300_2', '400_4', '500_8']\n",
    "\n",
    "## Normalisation parameters\n",
    "pos_max, pos_min = np.array([500, 4]), np.array([-60, -4])\n",
    "strain_min, strain_max = -0.18, 0.18\n",
    "strain_mean, strain_std = 0.0035714929721944264, 0.045594130780353334\n",
    "\n",
    "simulations = glob.glob(in_dir + '*')\n",
    "random.shuffle(simulations)\n",
    "simulations.sort()\n",
    "ds_train, ds_valid, ds_test = {}, {}, {}\n",
    "vels = np.array([]).reshape(0, 2)\n",
    "accs = np.array([]).reshape(0, 2)\n",
    "train_info, valid_info, test_info = [], [], []\n",
    "\n",
    "for idx, simulation in enumerate(simulations):\n",
    "    print(f\"{idx} Reading {simulation}...\")\n",
    "    \n",
    "    trajectory_name = simulation.split('/')[-1]\n",
    "    positions, particle_types, strains = parse_simulation(simulation)\n",
    "    \n",
    "    # Preprocessing positions\n",
    "    positions = positions[::STEP_SIZE,::1,::1] \n",
    "    positions[:, -5:, 1] = [-4, -2, 0, 2, 4]   ## Modify the y coordinate of the last 4 particles (boundary)\n",
    "    positions = (positions - pos_min) / (pos_max - pos_min)  # Normalize based on overall min and max of all simulations\n",
    "    # y_scalling_factor = (pos_max - pos_min)[0] / (pos_max - pos_min)[1]\n",
    "    # positions[:,:,1] = positions[:,:,1] / y_scalling_factor   \n",
    "    \n",
    "    # Change the last 4 particle to boundary particle\n",
    "    particle_types[-5:] = 2\n",
    "\n",
    "    # Preprocessing strains\n",
    "    strains = strains[::STEP_SIZE, ::1]\n",
    "    # strains = (strains - strain_mean) / strain_std   ## standardize based on overall mean and std\n",
    "    # strains = (strains - strain_min) / (strain_max - strain_min)   # Normalize based on overall min and max of all simulations\n",
    "    \n",
    "    print(f\"Position min:{positions.min(axis=(0,1))}, max:{positions.max(axis=(0,1))}\")\n",
    "    print(f\"Strain min:{strains.min(axis=(0,1))}, max:{strains.max(axis=(0,1))}\")\n",
    "    print(f\"Position shape:{positions.shape}, type shape:{particle_types.shape}\")\n",
    "    print(f\"Unique particle types: {np.unique(particle_types)}\")\n",
    "    \n",
    "    # Data splits: train, valid, test\n",
    "    key = 'trajectory_' + str(idx)\n",
    "    if any(name in trajectory_name for name in val_set):\n",
    "        ds_valid[key] = [positions, particle_types, strains]\n",
    "        valid_info.append(trajectory_name)\n",
    "    if any(name in trajectory_name for name in test_set):\n",
    "        ds_test[key] = [positions, particle_types, strains]\n",
    "        test_info.append(trajectory_name)\n",
    "    else:\n",
    "        ds_train[key] = [positions, particle_types, strains]   \n",
    "        train_info.append(trajectory_name)\n",
    "        \n",
    "    # Extract Vel and Acc statistics\n",
    "    # positions of shape [timestep, particles, dimensions]\n",
    "    vel_trajectory = positions[1:,:,:] - positions[:-1,:,:]\n",
    "    acc_trajectory = vel_trajectory[1:,:,:]- vel_trajectory[:-1,:,:]\n",
    "    \n",
    "    vels = np.concatenate((vels, vel_trajectory.reshape(-1, 2)), axis=0)\n",
    "    accs = np.concatenate((accs, acc_trajectory.reshape(-1, 2)), axis=0)\n",
    "    \n",
    "vel_mean = list(vels.mean(axis=0))\n",
    "vel_std = list(vels.std(axis=0))\n",
    "acc_mean = list(accs.mean(axis=0))\n",
    "acc_std = list(accs.std(axis=0))\n",
    "\n",
    "np.savez(out_dir + 'train.npz', **ds_train)\n",
    "np.savez(out_dir + 'valid.npz', **ds_valid)\n",
    "np.savez(out_dir + 'test.npz', **ds_test)\n",
    "\n",
    "print(f\"{len(ds_train)} trajectories parsed and saved to train.npz.\")\n",
    "print(f\"{len(ds_valid)} trajectories parsed and saved to valid.npz.\")\n",
    "print(f\"{len(ds_test)}  trajectories parsed and saved to test.npz.\")\n",
    "\n",
    "print(f\"Positions shape {positions.shape}, Particle types shape {particle_types.shape}, Strains shape {strains.shape}\")\n",
    "\n",
    "# Save meta data\n",
    "in_file = '/home/jovyan/share/gns_data/WaterDropSample/metadata.json'\n",
    "out_file = f'/home/jovyan/share/gns_data/{dataset}/metadata.json'\n",
    "\n",
    "with open(in_file, 'r') as f:\n",
    "    meta_data = json.load(f)\n",
    "\n",
    "# meta_data['bounds'] = [[-200, 200], [0, 100]]\n",
    "# The origin of simulation domain is at bottom center, and x in [-165, 165], y in [-10, 85].\n",
    "# Particle radius r is 1.25 mm, and the connection Radius R is around 6r to 7r, or [7.5, 8.75] (24 neighbors, maybe more)\n",
    "# In GNN, the suggested connection radius is 4.5r, or 5.625 mm (aounrd 20 neighbors)\n",
    "# If R is 6mm before normalization, then it is 0.016 where 6/370 = x/1\n",
    "meta_data['sequence_length'] = positions.shape[0]\n",
    "meta_data['default_connectivity_radius'] = 0.03  # 0.04 (normalized) or 7.5 (unnormalized) for around 24 neighbours\n",
    "meta_data['vel_mean'] = vel_mean\n",
    "meta_data['vel_std'] = vel_std\n",
    "meta_data['acc_mean'] = acc_mean\n",
    "meta_data['acc_std'] = acc_std\n",
    "meta_data['dim'] = 2\n",
    "meta_data['dt'] = 0.001 * STEP_SIZE\n",
    "meta_data['bounds'] = [[0, 1], [0, 1]]\n",
    "meta_data['file_train'] = train_info\n",
    "meta_data['file_valid'] = valid_info\n",
    "meta_data['file_test'] = test_info\n",
    "print(meta_data)\n",
    "\n",
    "with open(out_file, 'w') as f:\n",
    "    json.dump(meta_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293f1c1-19f2-485e-a173-9ea89053c5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
